{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "import zipfile\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sktime.classifiers import TSDummyClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SUFFIX = '_TRAIN.arff'\n",
    "TEST_SUFFIC  = '_TEST.arff'\n",
    "PROXY_URL = None #'ldn2tra3:3128'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I know that getting the data from www.timeseriesclassification.com is already implemented but wanted to make sure I understand how the data should be stored in pandas and I also needed the option to download through a proxy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download\n",
    "\n",
    "dtsName = 'GunPoint'\n",
    "dtsExt = '.zip'\n",
    "TSCurl = 'http://www.timeseriesclassification.com/Downloads/'\n",
    "url = f'{TSCurl}{dtsName}{dtsExt}'\n",
    "\n",
    "cache_path = f'.{os.sep}.sktime_temp_data{os.sep}'\n",
    "store_loc = f'{cache_path}{dtsName}{os.sep}'\n",
    "file_loc = f'{store_loc}{dtsName}{dtsExt}'\n",
    "if not os.path.exists(store_loc):\n",
    "    os.makedirs(store_loc)\n",
    "\n",
    "\n",
    "if PROXY_URL is not None:\n",
    "    print('proxy')\n",
    "    proxy = urllib.request.ProxyHandler({'http': proxy_url})\n",
    "    opener = urllib.request.build_opener(proxy)\n",
    "    urllib.request.install_opener(opener)\n",
    "\n",
    "if not os.path.exists(file_loc):\n",
    "    urllib.request.urlretrieve(url, file_loc)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unzip\n",
    "zip_ref = zipfile.ZipFile(file_loc, 'r')\n",
    "zip_ref.extractall(store_loc)\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import from arff\n",
    "TARGET_ATTRIBUTE_NAME = 'target'\n",
    "data, meta = arff.loadarff(f'{store_loc}{dtsName}{TRAIN_SUFFIX}')\n",
    "df = pd.DataFrame(data)\n",
    "target_ser = pd.Series(df[TARGET_ATTRIBUTE_NAME])\n",
    "target_ser = target_ser.apply(int)\n",
    "data_df = df.drop(TARGET_ATTRIBUTE_NAME,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_items = data_df.shape[0]\n",
    "# sktime_df = pd.DataFrame({'dim1':np.empty(num_items),'target':target_ser})\n",
    "sktime_df = pd.DataFrame(columns=['dim1','target'])\n",
    "for i in range(num_items):\n",
    "        sktime_df.at[i,'dim1'] = 1\n",
    "        sktime_df.at[i,'dim1'] = data_df.iloc[i,:]\n",
    "        sktime_df.at[i,'target'] = target_ser.iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sktime_df['dim1']\n",
    "y = sktime_df['target']\n",
    "model = TSDummyClassifier(strategy='most')\n",
    "model.fit(X, y)\n",
    "preds = model.predict(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminary design of the evaluation class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "class Evaluate:\n",
    "    \"\"\"\n",
    "    skeletton for the evaluation class. \n",
    "    \n",
    "    The constructor can take either the fitted estimator or a results object. \n",
    "    \n",
    "    If the strucutre of the results object is agreed on X, y, estimator type and other relevant properties will be obtained directly from the results object and set in the constructor.\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fitted_estimator: sktime estimator\n",
    "        fitted estimator\n",
    "    X: pandas DataFrame\n",
    "        features\n",
    "    y: pandas Series\n",
    "        predictors\n",
    "    \"\"\"\n",
    "    def __init__(self, fitted_estimator, X, y):\n",
    "        self._X = X\n",
    "        self._y = y\n",
    "        self._fitted_estimator = fitted_estimator\n",
    "        self._predictions = fitted_estimator.predict(X)\n",
    "        \n",
    "        self._estim_type = 'Classification' #should be obtained by checking the type of the estimator object or by accessing a property\n",
    "    def eval(self):\n",
    "        \"\"\"\n",
    "        main evaluation method. Should check the type of the estimator object that was passed (classification/regression) and calculate the respective tests.  \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        results: dictionary\n",
    "            dictionary with the statistical tests\n",
    "        \"\"\"\n",
    "        y = np.array(self._y, np.int16)\n",
    "        pred = np.array(self._predictions, np.int16)\n",
    "        if self._estim_type == 'Classification':\n",
    "            results = {\n",
    "                'accuracy_score': accuracy_score(y_true=y, y_pred=pred),\n",
    "                'f1_score': f1_score(y_true=y, y_pred=pred)\n",
    "            }\n",
    "        return results\n",
    "    \n",
    "    def check_residuals(self):\n",
    "        \"\"\"\n",
    "        Checks the residuals of the fitted model for autocorrelation for example by performing a Ljung-Box test\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Evaluate(fitted_estimator=model, X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kazakovv\\appdata\\local\\conda\\conda\\envs\\venv_sktime\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy_score': 0.52, 'f1_score': 0.0}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
